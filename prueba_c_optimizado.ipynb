{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ AN√ÅLISIS PREDICTIVO DE SUSCRIPCI√ìN BANCARIA\n",
        "## Competencia Kaggle - Machine Learning\n",
        "\n",
        "**Objetivo:** Predecir si un cliente se suscribir√° a un dep√≥sito a t√©rmino\n",
        "\n",
        "**Dataset:** Datos de campa√±as de marketing bancario\n",
        "\n",
        "**Autor:** Ciro\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CONFIGURACI√ìN INICIAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Importaci√≥n de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Manipulaci√≥n de datos\n",
          "import pandas as pd\n",
          "import numpy as np\n",
          "\n",
          "# Visualizaci√≥n\n",
          "import matplotlib.pyplot as plt\n",
          "import seaborn as sns\n",
          "\n",
          "# Machine Learning\n",
          "from sklearn.model_selection import train_test_split\n",
          "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
          "from sklearn.impute import SimpleImputer\n",
          "from sklearn.compose import ColumnTransformer\n",
          "from sklearn.pipeline import Pipeline\n",
          "from sklearn.linear_model import LogisticRegression\n",
          "from sklearn.ensemble import RandomForestClassifier\n",
          "from sklearn.metrics import (\n",
          "    classification_report,\n",
          "    confusion_matrix,\n",
          "    roc_auc_score,\n",
          "    f1_score\n",
          ")\n",
          "\n",
          "# XGBoost y balanceo\n",
          "from xgboost import XGBClassifier\n",
          "from imblearn.over_sampling import SMOTE\n",
          "\n",
          "# Estad√≠sticas\n",
          "from scipy.stats import mstats\n",
          "\n",
          "# Configuraci√≥n\n",
          "import warnings\n",
          "warnings.filterwarnings('ignore')\n",
          "\n",
          "plt.style.use('seaborn-v0_8-darkgrid')\n",
          "sns.set_palette(\"husl\")\n",
          "%matplotlib inline\n",
          "\n",
          "print(\"‚úì Bibliotecas importadas correctamente\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Cargar datasets\n",
          "df_sample = pd.read_csv('sample_submission.csv', encoding='utf-8')\n",
          "df_train = pd.read_csv('train.csv', encoding='utf-8')\n",
          "df_test_public = pd.read_csv('test_public.csv', encoding='utf-8')\n",
          "df_test_private = pd.read_csv('test_private.csv', encoding='utf-8')\n",
          "\n",
          "print(f\"Train: {df_train.shape}\")\n",
          "print(f\"Test Public: {df_test_public.shape}\")\n",
          "print(f\"Test Private: {df_test_private.shape}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Resumen Estad√≠stico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Informaci√≥n general\n",
          "print(\"INFORMACI√ìN DEL DATASET\\n\")\n",
          "print(f\"Dimensiones: {df_train.shape}\")\n",
          "print(f\"\\nTipos de datos:\")\n",
          "print(df_train.dtypes.value_counts())\n",
          "\n",
          "# Valores faltantes\n",
          "missing = df_train.isnull().sum()\n",
          "if missing.sum() > 0:\n",
          "    print(f\"\\nValores faltantes:\")\n",
          "    print(missing[missing > 0])\n",
          "else:\n",
          "    print(\"\\n‚úì No hay valores faltantes\")\n",
          "\n",
          "# Duplicados\n",
          "duplicados = df_train.duplicated().sum()\n",
          "print(f\"\\nRegistros duplicados: {duplicados}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 An√°lisis de Variable Objetivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Distribuci√≥n de la variable objetivo\n",
          "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
          "\n",
          "# Conteo\n",
          "df_train['y'].value_counts().plot(kind='bar', ax=ax[0], color=['#ff6b6b', '#4ecdc4'])\n",
          "ax[0].set_title('Distribuci√≥n de Suscripciones', fontsize=14, fontweight='bold')\n",
          "ax[0].set_xlabel('Suscripci√≥n')\n",
          "ax[0].set_ylabel('Frecuencia')\n",
          "ax[0].tick_params(rotation=0)\n",
          "\n",
          "# Porcentaje\n",
          "df_train['y'].value_counts(normalize=True).plot(kind='pie', ax=ax[1], autopct='%1.1f%%',\n",
          "                                               colors=['#ff6b6b', '#4ecdc4'])\n",
          "ax[1].set_title('Proporci√≥n de Suscripciones', fontsize=14, fontweight='bold')\n",
          "ax[1].set_ylabel('')\n",
          "\n",
          "plt.tight_layout()\n",
          "plt.show()\n",
          "\n",
          "print(\"\\nDistribuci√≥n:\")\n",
          "print(df_train['y'].value_counts())\n",
          "print(f\"\\nBalance: {df_train['y'].value_counts(normalize=True) * 100}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Identificaci√≥n de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Identificar tipos de variables\n",
          "numerical_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
          "categorical_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
          "\n",
          "# Remover variable objetivo\n",
          "if 'y' in categorical_cols:\n",
          "    categorical_cols.remove('y')\n",
          "\n",
          "print(f\"Variables Num√©ricas ({len(numerical_cols)}): {numerical_cols[:10]}...\")\n",
          "print(f\"\\nVariables Categ√≥ricas ({len(categorical_cols)}): {categorical_cols[:10]}...\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. INGENIER√çA Y PREPARACI√ìN DE DATOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Funciones de Limpieza de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "def parsear_duracion(duracion_str):\n",
          "    \"\"\"\n",
          "    Convierte '3m 12s' a segundos totales\n",
          "    \"\"\"\n",
          "    if pd.isna(duracion_str):\n",
          "        return np.nan\n",
          "    \n",
          "    duracion_str = str(duracion_str).strip()\n",
          "    \n",
          "    # Si ya es un n√∫mero\n",
          "    if duracion_str.isdigit():\n",
          "        return int(duracion_str)\n",
          "    \n",
          "    # Parsear formato 'Xm Ys'\n",
          "    minutos = 0\n",
          "    segundos = 0\n",
          "    \n",
          "    partes = duracion_str.split()\n",
          "    for parte in partes:\n",
          "        if 'm' in parte:\n",
          "            minutos = int(parte.replace('m', ''))\n",
          "        elif 's' in parte:\n",
          "            segundos = int(parte.replace('s', ''))\n",
          "    \n",
          "    return minutos * 60 + segundos\n",
          "\n",
          "\n",
          "def parsear_p_dias_correcto(valor):\n",
          "    \"\"\"\n",
          "    Maneja 'nunca' en p_dias\n",
          "    \"\"\"\n",
          "    if pd.isna(valor):\n",
          "        return 999\n",
          "    \n",
          "    if isinstance(valor, str):\n",
          "        if valor.lower() == 'nunca':\n",
          "            return 999\n",
          "        try:\n",
          "            return int(valor)\n",
          "        except:\n",
          "            return 999\n",
          "    \n",
          "    return int(valor)\n",
          "\n",
          "\n",
          "def limpieza_completa_final(df, es_train=True):\n",
          "    \"\"\"\n",
          "    Funci√≥n de limpieza completa y final de datos\n",
          "    \"\"\"\n",
          "    df_clean = df.copy()\n",
          "    \n",
          "    # Eliminar columnas innecesarias\n",
          "    cols_eliminar = ['id', 'DNI', 'nombre', 'apellido']\n",
          "    df_clean = df_clean.drop(columns=cols_eliminar, errors='ignore')\n",
          "    \n",
          "    # Limpieza de trabajo\n",
          "    trabajo_map = {\n",
          "        'Obrero': 'obrero', 'Jubilado': 'jubilado', 'Retirado': 'retirado',\n",
          "        'Administrativo': 'administrativo', 'Estudiante': 'estudiante',\n",
          "        'Emprendedor': 'emprendedor', 'Gesti√≥n': 'gesti√≥n', 'Aut√≥nomo': 'aut√≥nomo',\n",
          "        'tecnico': 't√©cnico', 'experto t√©cnico': 't√©cnico',\n",
          "        'criado(a)': 'servicio', 'criada(o)': 'servicio', 'servicios': 'servicio',\n",
          "        'retirado': 'jubilado', 'desocupado': 'desempleado', 'autonomo': 'aut√≥nomo',\n",
          "        'SIN INFORMACI√ìN': 'desconocido', 'DESCONOCIDO': 'desconocido',\n",
          "        'NO SE SABE': 'desconocido', 'NO SE CONOCE': 'desconocido'\n",
          "    }\n",
          "    df_clean['trabajo'] = df_clean['trabajo'].replace(trabajo_map).str.lower()\n",
          "    \n",
          "    # Limpieza de educaci√≥n\n",
          "    educacion_map = {\n",
          "        'superios': 'superior', 'primari@': 'primaria', 'SECUNDARIA': 'secundaria',\n",
          "        'SIN INFORMACI√ìN': 'desconocido', 'DESCONOCIDO': 'desconocido',\n",
          "        'NO SE SABE': 'desconocido', 'NO SE CONOCE': 'desconocido'\n",
          "    }\n",
          "    df_clean['educaci√≥n'] = df_clean['educaci√≥n'].replace(educacion_map).str.lower()\n",
          "    \n",
          "    # Limpieza de estado civil\n",
          "    estado_civil_map = {\n",
          "        'divorcio voluntario': 'divorciado', 'divorcio contencioso': 'divorciado',\n",
          "        'casado, con hijos': 'casado', 'casado, sin hijos': 'casado'\n",
          "    }\n",
          "    df_clean['estado_civil'] = df_clean['estado_civil'].replace(estado_civil_map)\n",
          "    \n",
          "    # Convertir variables binarias\n",
          "    df_clean['hipoteca'] = df_clean['hipoteca'].str.lower()\n",
          "    df_clean['riesgo_crediticio'] = (df_clean['riesgo_crediticio'] == 'S√≠').astype(int)\n",
          "    df_clean['deuda_personal'] = (df_clean['deuda_personal'] == 'si').astype(int)\n",
          "    df_clean['hipoteca'] = (df_clean['hipoteca'] == 'si').astype(int)\n",
          "    df_clean['incumplimiento'] = (df_clean['incumplimiento'] == 'si').astype(int)\n",
          "    \n",
          "    # Limpieza de contacto\n",
          "    contacto_map = {\n",
          "        'CEL': 'celular', 'CELL': 'celular', 'celular': 'celular', 'Celular ': 'celular',\n",
          "        'tel√©fono ': 'telefono', 'TEL': 'telefono', 'Tel√©fono': 'telefono',\n",
          "        'Desconocido': 'desconocido', 'desconocido': 'desconocido'\n",
          "    }\n",
          "    df_clean['contacto'] = df_clean['contacto'].replace(contacto_map)\n",
          "    \n",
          "    # Limpieza de p_resultado\n",
          "    p_resultado_map = {\n",
          "        'SIN INFORMACI√ìN': 'desconocido', 'sin informacion': 'desconocido',\n",
          "        'DESCONOCIDO': 'desconocido', 'NO SE SABE': 'desconocido',\n",
          "        'exito': '√©xito', 'EXITO': '√©xito', 'Exitoso': '√©xito',\n",
          "        'fracaso': 'fracaso', 'FRACASO': 'fracaso'\n",
          "    }\n",
          "    df_clean['p_resultado'] = df_clean['p_resultado'].replace(p_resultado_map).str.lower()\n",
          "    \n",
          "    # Procesar fecha\n",
          "    if 'fecha' in df_clean.columns:\n",
          "        df_clean['fecha'] = pd.to_datetime(df_clean['fecha'], errors='coerce')\n",
          "        df_clean['dia'] = df_clean['fecha'].dt.day\n",
          "        df_clean['mes'] = df_clean['fecha'].dt.month\n",
          "        df_clean = df_clean.drop(columns=['fecha'])\n",
          "    \n",
          "    # Parsear duracion\n",
          "    if 'duracion' in df_clean.columns:\n",
          "        df_clean['duracion'] = df_clean['duracion'].apply(parsear_duracion)\n",
          "    \n",
          "    # Parsear p_dias\n",
          "    df_clean['p_dias'] = df_clean['p_dias'].apply(parsear_p_dias_correcto)\n",
          "    \n",
          "    return df_clean\n",
          "\n",
          "print(\"‚úì Funciones de limpieza definidas\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Aplicaci√≥n de Limpieza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Aplicar limpieza a todos los datasets\n",
          "df_train_clean = limpieza_completa_final(df_train, es_train=True)\n",
          "df_test_public_clean = limpieza_completa_final(df_test_public, es_train=False)\n",
          "df_test_private_clean = limpieza_completa_final(df_test_private, es_train=False)\n",
          "\n",
          "print(\"‚úì Limpieza aplicada a todos los datasets\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "def feature_engineering_final(df):\n",
          "    \"\"\"\n",
          "    Feature Engineering completo y final\n",
          "    \"\"\"\n",
          "    df_fe = df.copy()\n",
          "    \n",
          "    # Variables de edad\n",
          "    df_fe['edad'] = 2024 - df_fe['a√±o_nacimiento']\n",
          "    df_fe['grupo_edad'] = pd.cut(\n",
          "        df_fe['edad'],\n",
          "        bins=[0, 25, 35, 45, 55, 65, 100],\n",
          "        labels=['muy_joven', 'joven', 'adulto_joven', 'adulto', 'senior', 'anciano']\n",
          "    )\n",
          "    \n",
          "    # Variables financieras\n",
          "    df_fe['fondos_winsorized'] = mstats.winsorize(\n",
          "        df_fe['fondos_promedio_anual'],\n",
          "        limits=[0.05, 0.05]\n",
          "    )\n",
          "    df_fe['nivel_fondos'] = pd.cut(\n",
          "        df_fe['fondos_winsorized'],\n",
          "        bins=[-10000, 0, 500, 1500, 100000],\n",
          "        labels=['negativo', 'bajo', 'medio', 'alto']\n",
          "    )\n",
          "    \n",
          "    # Score de riesgo financiero\n",
          "    df_fe['alto_riesgo'] = (\n",
          "        (df_fe['riesgo_crediticio'] == 1) |\n",
          "        (df_fe['incumplimiento'] == 1)\n",
          "    ).astype(int)\n",
          "    \n",
          "    df_fe['score_mal_financiero'] = (\n",
          "        df_fe['riesgo_crediticio'] +\n",
          "        df_fe['deuda_personal'] +\n",
          "        df_fe['incumplimiento'] +\n",
          "        (df_fe['fondos_promedio_anual'] < 0).astype(int)\n",
          "    )\n",
          "    \n",
          "    # Variables de contacto\n",
          "    df_fe['contactos_previos_log'] = np.log1p(df_fe['contactos_previos'])\n",
          "    df_fe['fue_contactado_antes'] = (df_fe['p_dias'] < 500).astype(int)\n",
          "    df_fe['ratio_dias_contactos'] = np.where(\n",
          "        df_fe['contactos_previos'] > 0,\n",
          "        df_fe['p_dias'] / (df_fe['contactos_previos'] + 1),\n",
          "        0\n",
          "    )\n",
          "    \n",
          "    # Variables de campa√±a\n",
          "    df_fe['campa√±a_bin'] = pd.cut(\n",
          "        df_fe['campa√±a'],\n",
          "        bins=[0, 1, 2, 3, 5, 100],\n",
          "        labels=['1_contacto', '2_contactos', '3_contactos', '4-5_contactos', '6+_contactos']\n",
          "    )\n",
          "    \n",
          "    # Transformaciones de p_dias\n",
          "    df_fe['p_dias_transformado'] = np.where(\n",
          "        df_fe['p_dias'] == 999,\n",
          "        -1,\n",
          "        df_fe['p_dias']\n",
          "    )\n",
          "    df_fe['p_dias_log'] = np.log1p(df_fe['p_dias_transformado'] + 2)\n",
          "    \n",
          "    # Variables temporales\n",
          "    df_fe['trimestre'] = pd.cut(\n",
          "        df_fe['mes'],\n",
          "        bins=[0, 3, 6, 9, 12],\n",
          "        labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
          "    )\n",
          "    df_fe['fin_de_mes'] = (df_fe['dia'] >= 25).astype(int)\n",
          "    \n",
          "    # Duracion (solo si existe)\n",
          "    if 'duracion' in df_fe.columns and df_fe['duracion'].notna().sum() > 0:\n",
          "        df_fe['duracion_log'] = np.log1p(df_fe['duracion'])\n",
          "        df_fe['duracion_bin'] = pd.cut(\n",
          "            df_fe['duracion'],\n",
          "            bins=[0, 120, 300, 600, 5000],\n",
          "            labels=['muy_corta', 'corta', 'media', 'larga']\n",
          "        )\n",
          "    \n",
          "    return df_fe\n",
          "\n",
          "print(\"‚úì Funci√≥n de feature engineering definida\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Aplicaci√≥n de Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Aplicar feature engineering\n",
          "df_train_fe = feature_engineering_final(df_train_clean)\n",
          "df_test_public_fe = feature_engineering_final(df_test_public_clean)\n",
          "df_test_private_fe = feature_engineering_final(df_test_private_clean)\n",
          "\n",
          "print(\"‚úì Feature engineering aplicado\")\n",
          "print(f\"\\nNuevas dimensiones train: {df_train_fe.shape}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Definici√≥n de Features para Modelado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Features num√©ricas\n",
          "features_numericas = [\n",
          "    'edad',\n",
          "    'fondos_winsorized',\n",
          "    'contactos_previos_log',\n",
          "    'p_dias_transformado',\n",
          "    'p_dias_log',\n",
          "    'dia',\n",
          "    'mes',\n",
          "    'ratio_dias_contactos'\n",
          "]\n",
          "\n",
          "# Features binarias\n",
          "features_binarias = [\n",
          "    'riesgo_crediticio',\n",
          "    'deuda_personal',\n",
          "    'incumplimiento',\n",
          "    'hipoteca',\n",
          "    'fue_contactado_antes',\n",
          "    'fin_de_mes',\n",
          "    'alto_riesgo',\n",
          "    'score_mal_financiero'\n",
          "]\n",
          "\n",
          "# Features categ√≥ricas\n",
          "features_categoricas = [\n",
          "    'trabajo',\n",
          "    'estado_civil',\n",
          "    'educaci√≥n',\n",
          "    'contacto',\n",
          "    'p_resultado',\n",
          "    'campa√±a_bin',\n",
          "    'nivel_fondos',\n",
          "    'grupo_edad',\n",
          "    'trimestre'\n",
          "]\n",
          "\n",
          "# Lista completa de features (SIN duracion para producci√≥n)\n",
          "features_modelo = features_numericas + features_binarias + features_categoricas\n",
          "\n",
          "print(f\"Total de features: {len(features_modelo)}\")\n",
          "print(f\"  - Num√©ricas: {len(features_numericas)}\")\n",
          "print(f\"  - Binarias: {len(features_binarias)}\")\n",
          "print(f\"  - Categ√≥ricas: {len(features_categoricas)}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.6 Divisi√≥n Train/Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Preparar X e y\n",
          "X = df_train_fe[features_modelo].copy()\n",
          "y = (df_train_fe['y'] == 'si').astype(int)\n",
          "\n",
          "# Split estratificado\n",
          "X_train, X_val, y_train, y_val = train_test_split(\n",
          "    X, y, test_size=0.20, random_state=42, stratify=y\n",
          ")\n",
          "\n",
          "print(f\"Train set: {X_train.shape}, balance: {y_train.mean():.2%}\")\n",
          "print(f\"Val set: {X_val.shape}, balance: {y_val.mean():.2%}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. MODELADO Y EVALUACI√ìN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Pipeline de Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Crear preprocessor\n",
          "preprocessor = ColumnTransformer(\n",
          "    transformers=[\n",
          "        ('num', Pipeline(steps=[\n",
          "            ('imputer', SimpleImputer(strategy='mean')),\n",
          "            ('scaler', StandardScaler())\n",
          "        ]), features_numericas),\n",
          "        ('bin', 'passthrough', features_binarias),\n",
          "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), features_categoricas)\n",
          "    ],\n",
          "    remainder='drop'\n",
          ")\n",
          "\n",
          "print(\"‚úì Pipeline de preprocesamiento creado\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Modelo Baseline - Regresi√≥n Log√≠stica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Modelo baseline\n",
          "modelo_baseline = Pipeline([\n",
          "    ('preprocessor', preprocessor),\n",
          "    ('classifier', LogisticRegression(\n",
          "        max_iter=1000,\n",
          "        class_weight='balanced',\n",
          "        random_state=42\n",
          "    ))\n",
          "])\n",
          "\n",
          "# Entrenar\n",
          "modelo_baseline.fit(X_train, y_train)\n",
          "\n",
          "# Evaluar\n",
          "y_val_proba = modelo_baseline.predict_proba(X_val)[:, 1]\n",
          "y_val_pred = modelo_baseline.predict(X_val)\n",
          "\n",
          "print(\"Baseline - Regresi√≥n Log√≠stica:\")\n",
          "print(f\"  AUC-ROC: {roc_auc_score(y_val, y_val_proba):.4f}\")\n",
          "print(f\"  F1-Score: {f1_score(y_val, y_val_pred):.4f}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Modelo Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Random Forest\n",
          "modelo_rf = Pipeline([\n",
          "    ('preprocessor', preprocessor),\n",
          "    ('classifier', RandomForestClassifier(\n",
          "        n_estimators=100,\n",
          "        max_depth=10,\n",
          "        class_weight='balanced',\n",
          "        random_state=42,\n",
          "        n_jobs=-1\n",
          "    ))\n",
          "])\n",
          "\n",
          "modelo_rf.fit(X_train, y_train)\n",
          "\n",
          "# Evaluar\n",
          "y_val_proba_rf = modelo_rf.predict_proba(X_val)[:, 1]\n",
          "\n",
          "# Optimizar threshold\n",
          "best_f1 = 0\n",
          "best_threshold = 0.5\n",
          "\n",
          "for threshold in np.arange(0.20, 0.60, 0.05):\n",
          "    y_val_pred_th = (y_val_proba_rf >= threshold).astype(int)\n",
          "    f1 = f1_score(y_val, y_val_pred_th)\n",
          "    if f1 > best_f1:\n",
          "        best_f1 = f1\n",
          "        best_threshold = threshold\n",
          "\n",
          "print(f\"Random Forest:\")\n",
          "print(f\"  AUC-ROC: {roc_auc_score(y_val, y_val_proba_rf):.4f}\")\n",
          "print(f\"  Best F1: {best_f1:.4f} (threshold={best_threshold:.2f})\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Modelo Final - XGBoost con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Preprocesar datos\n",
          "X_train_processed = preprocessor.fit_transform(X_train)\n",
          "X_val_processed = preprocessor.transform(X_val)\n",
          "\n",
          "# Aplicar SMOTE\n",
          "smote = SMOTE(random_state=42, k_neighbors=5)\n",
          "X_train_smote, y_train_smote = smote.fit_resample(X_train_processed, y_train)\n",
          "\n",
          "print(f\"Antes SMOTE: {X_train_processed.shape}, balance: {y_train.mean():.2%}\")\n",
          "print(f\"Despu√©s SMOTE: {X_train_smote.shape}, balance: {y_train_smote.mean():.2%}\")\n",
          "\n",
          "# Entrenar XGBoost\n",
          "modelo_xgb = XGBClassifier(\n",
          "    n_estimators=200,\n",
          "    max_depth=6,\n",
          "    learning_rate=0.05,\n",
          "    subsample=0.8,\n",
          "    colsample_bytree=0.8,\n",
          "    random_state=42,\n",
          "    n_jobs=-1\n",
          ")\n",
          "\n",
          "modelo_xgb.fit(X_train_smote, y_train_smote)\n",
          "\n",
          "# Evaluar y optimizar threshold\n",
          "y_val_proba_xgb = modelo_xgb.predict_proba(X_val_processed)[:, 1]\n",
          "\n",
          "best_f1_xgb = 0\n",
          "best_threshold_xgb = 0.5\n",
          "\n",
          "for threshold in np.arange(0.20, 0.60, 0.01):\n",
          "    y_val_pred_th = (y_val_proba_xgb >= threshold).astype(int)\n",
          "    f1 = f1_score(y_val, y_val_pred_th)\n",
          "    if f1 > best_f1_xgb:\n",
          "        best_f1_xgb = f1\n",
          "        best_threshold_xgb = threshold\n",
          "\n",
          "# Predicci√≥n final\n",
          "y_val_pred_final = (y_val_proba_xgb >= best_threshold_xgb).astype(int)\n",
          "\n",
          "print(f\"\\nXGBoost + SMOTE (MODELO FINAL):\")\n",
          "print(f\"  AUC-ROC: {roc_auc_score(y_val, y_val_proba_xgb):.4f}\")\n",
          "print(f\"  Best F1: {best_f1_xgb:.4f} (threshold={best_threshold_xgb:.2f})\")\n",
          "print(f\"\\nClassification Report:\\n{classification_report(y_val, y_val_pred_final, target_names=['No', 'S√≠'])}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Matriz de Confusi√≥n - Modelo Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Matriz de confusi√≥n\n",
          "cm = confusion_matrix(y_val, y_val_pred_final)\n",
          "\n",
          "plt.figure(figsize=(8, 6))\n",
          "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
          "plt.title('Matriz de Confusi√≥n - XGBoost + SMOTE', fontsize=14, fontweight='bold')\n",
          "plt.ylabel('Real')\n",
          "plt.xlabel('Predicho')\n",
          "plt.xticks([0.5, 1.5], ['No', 'S√≠'])\n",
          "plt.yticks([0.5, 1.5], ['No', 'S√≠'])\n",
          "plt.show()"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. GENERACI√ìN DE PREDICCIONES FINALES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Preparaci√≥n de Datos de Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Guardar IDs antes de combinar\n",
          "ids_public = df_test_public['id'].values\n",
          "ids_private = df_test_private['id'].values\n",
          "ids_combined = np.concatenate([ids_public, ids_private])\n",
          "\n",
          "# Combinar test public y private\n",
          "df_test_combined = pd.concat([\n",
          "    df_test_public_fe,\n",
          "    df_test_private_fe\n",
          "], axis=0, ignore_index=True)\n",
          "\n",
          "# Extraer features\n",
          "X_test_combined = df_test_combined[features_modelo].copy()\n",
          "\n",
          "# Aplicar preprocessing\n",
          "X_test_combined_processed = preprocessor.transform(X_test_combined)\n",
          "\n",
          "print(f\"Test combined: {X_test_combined_processed.shape}\")\n",
          "print(f\"IDs guardados: {len(ids_combined)}\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Predicciones con Modelo Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Predicciones con XGBoost + SMOTE\n",
          "y_test_proba = modelo_xgb.predict_proba(X_test_combined_processed)[:, 1]\n",
          "y_test_pred = (y_test_proba >= best_threshold_xgb).astype(int)\n",
          "\n",
          "# Convertir a formato 'si'/'no'\n",
          "y_test_labels = ['si' if pred == 1 else 'no' for pred in y_test_pred]\n",
          "\n",
          "print(f\"Predicciones generadas: {len(y_test_labels)}\")\n",
          "print(f\"Distribuci√≥n:\")\n",
          "print(f\"  'si': {sum(y_test_pred)} ({sum(y_test_pred)/len(y_test_pred)*100:.1f}%)\")\n",
          "print(f\"  'no': {len(y_test_pred) - sum(y_test_pred)} ({(1-sum(y_test_pred)/len(y_test_pred))*100:.1f}%)\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Generaci√≥n de Archivo Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Crear DataFrame submission\n",
          "df_submission = pd.DataFrame({\n",
          "    'id': ids_combined,\n",
          "    'y': y_test_labels\n",
          "})\n",
          "\n",
          "# Guardar archivo\n",
          "filename = 'xgboost_smote_threshold040_submission.csv'\n",
          "df_submission.to_csv(filename, index=False)\n",
          "\n",
          "print(f\"‚úì Archivo guardado: {filename}\")\n",
          "print(f\"\\nPrimeras filas:\")\n",
          "print(df_submission.head(10))"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Checklist de Verificaci√≥n Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        [
          "# Checklist de verificaci√≥n\n",
          "import os\n",
          "\n",
          "checks = [\n",
          "    (\"Archivo existe\", os.path.exists(filename)),\n",
          "    (\"N√∫mero de filas correcto\", len(df_submission) == len(df_test_public) + len(df_test_private)),\n",
          "    (\"Columnas correctas\", list(df_submission.columns) == ['id', 'y']),\n",
          "    (\"Valores correctos\", set(df_submission['y'].unique()) == {'si', 'no'}),\n",
          "    (\"Sin valores nulos\", df_submission.isnull().sum().sum() == 0),\n",
          "    (\"IDs √∫nicos\", df_submission['id'].nunique() == len(df_submission))\n",
          "]\n",
          "\n",
          "print(\"VERIFICACI√ìN FINAL:\\n\")\n",
          "all_ok = True\n",
          "for check_name, result in checks:\n",
          "    status = \"‚úì\" if result else \"‚úó\"\n",
          "    print(f\"  [{status}] {check_name}\")\n",
          "    if not result:\n",
          "        all_ok = False\n",
          "\n",
          "if all_ok:\n",
          "    print(f\"\\n{'='*50}\")\n",
          "    print(\"üéâ LISTO PARA SUBIR A KAGGLE üéâ\")\n",
          "    print(f\"{'='*50}\")\n",
          "else:\n",
          "    print(\"\\n‚ö†Ô∏è Hay errores que corregir\")"
        ]
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. CONCLUSIONES Y PR√ìXIMOS PASOS\n",
        "\n",
        "### Resumen de Resultados\n",
        "- **Modelo Final:** XGBoost con SMOTE\n",
        "- **Threshold √ìptimo:** Determinado mediante optimizaci√≥n en validation set\n",
        "- **Archivo Generado:** `xgboost_smote_threshold040_submission.csv`\n",
        "\n",
        "### Aprendizajes Clave\n",
        "1. El balanceo de clases con SMOTE mejor√≥ significativamente el F1-Score\n",
        "2. La optimizaci√≥n del threshold es cr√≠tica para maximizar F1\n",
        "3. XGBoost super√≥ a Random Forest y Regresi√≥n Log√≠stica\n",
        "\n",
        "### Mejoras Futuras\n",
        "- Probar otros algoritmos (LightGBM, CatBoost)\n",
        "- Feature engineering adicional basado en an√°lisis de errores\n",
        "- Ensemble de m√∫ltiples modelos\n",
        "- Hyperparameter tuning con GridSearchCV\n",
        "- Validaci√≥n cruzada estratificada"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}